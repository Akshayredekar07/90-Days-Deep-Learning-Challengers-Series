{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43905bd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documents:\n",
      "D1: people watch campusx\n",
      "D2: campusx watch campusx\n",
      "D3: people write comment\n",
      "D4: campusx write comment\n",
      "\n",
      "Corpus:\n",
      "people watch campusx campusx watch campusx people write comment campusx write comment\n",
      "\n",
      "Vocabulary: ['campusx', 'comment', 'people', 'watch', 'write']\n",
      "Vocabulary Size (V): 5\n",
      "\n",
      "One-Hot Encoding Vectors:\n",
      "campusx: [1, 0, 0, 0, 0]\n",
      "comment: [0, 1, 0, 0, 0]\n",
      "people: [0, 0, 1, 0, 0]\n",
      "watch: [0, 0, 0, 1, 0]\n",
      "write: [0, 0, 0, 0, 1]\n",
      "\n",
      "Document D1 One-Hot Encoding:\n",
      "[[0 0 1 0 0]\n",
      " [0 0 0 1 0]\n",
      " [1 0 0 0 0]]\n",
      "Shape: (3, 5)\n",
      "\n",
      "Document D2 One-Hot Encoding:\n",
      "[[1 0 0 0 0]\n",
      " [0 0 0 1 0]\n",
      " [1 0 0 0 0]]\n",
      "Shape: (3, 5)\n",
      "\n",
      "Document D3 One-Hot Encoding:\n",
      "[[0 0 1 0 0]\n",
      " [0 0 0 0 1]\n",
      " [0 1 0 0 0]]\n",
      "Shape: (3, 5)\n",
      "\n",
      "Document D4 One-Hot Encoding:\n",
      "[[1 0 0 0 0]\n",
      " [0 0 0 0 1]\n",
      " [0 1 0 0 0]]\n",
      "Shape: (3, 5)\n",
      "\n",
      "7. Handling Out-of-Vocabulary (OOV) Words:\n",
      "New Document: 'hello campusx peoples'\n",
      "Known Words: ['campusx']\n",
      "Unknown Words (OOV): ['hello', 'peoples']\n",
      "\n",
      "Encoded New Document (only known words are encoded):\n",
      "[[1 0 0 0 0]]\n",
      "Shape: (1, 5)\n",
      "\n",
      "8. Demonstrating lack of semantic relationships:\n",
      "Simple One-Hot Encodings:\n",
      "walk: [1, 0, 0]\n",
      "run: [0, 1, 0]\n",
      "shoe: [0, 0, 1]\n",
      "\n",
      "Euclidean Distances:\n",
      "Distance between 'walk' and 'run': 1.41\n",
      "Distance between 'walk' and 'shoe': 1.41\n",
      "Distance between 'run' and 'walk': 1.41\n",
      "Distance between 'run' and 'shoe': 1.41\n",
      "Distance between 'shoe' and 'walk': 1.41\n",
      "Distance between 'shoe' and 'run': 1.41\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "# 1. Corpus and Documents\n",
    "documents = [\n",
    "    \"people watch campusx\",\n",
    "    \"campusx watch campusx\",\n",
    "    \"people write comment\",\n",
    "    \"campusx write comment\"\n",
    "]\n",
    "\n",
    "# Print the documents\n",
    "print(\"Documents:\")\n",
    "for i, doc in enumerate(documents):\n",
    "    print(f\"D{i+1}: {doc}\")\n",
    "\n",
    "# 2. Create the corpus by combining all documents\n",
    "corpus = \" \".join(documents)\n",
    "print(\"\\nCorpus:\")\n",
    "print(corpus)\n",
    "\n",
    "# 3. Create vocabulary (unique words)\n",
    "def create_vocabulary(corpus):\n",
    "    # Split the corpus into words and get unique words\n",
    "    words = corpus.split()\n",
    "    vocabulary = sorted(list(set(words)))\n",
    "    return vocabulary\n",
    "\n",
    "vocabulary = create_vocabulary(corpus)\n",
    "V = len(vocabulary)\n",
    "\n",
    "print(\"\\nVocabulary:\", vocabulary)\n",
    "print(f\"Vocabulary Size (V): {V}\")\n",
    "\n",
    "# 4. One-Hot Encoding Vectors\n",
    "def create_one_hot_encoding(word, vocabulary):\n",
    "    # Create a vector of zeros with length equal to vocabulary size\n",
    "    vector = [0] * len(vocabulary)\n",
    "    \n",
    "    # Set the position corresponding to the word to 1\n",
    "    if word in vocabulary:\n",
    "        word_index = vocabulary.index(word)\n",
    "        vector[word_index] = 1\n",
    "    \n",
    "    return vector\n",
    "\n",
    "# Generate one-hot encodings for each word in vocabulary\n",
    "one_hot_encodings = {}\n",
    "for word in vocabulary:\n",
    "    one_hot_encodings[word] = create_one_hot_encoding(word, vocabulary)\n",
    "\n",
    "# Print one-hot encodings\n",
    "print(\"\\nOne-Hot Encoding Vectors:\")\n",
    "for word, vector in one_hot_encodings.items():\n",
    "    print(f\"{word}: {vector}\")\n",
    "\n",
    "# 5. Document Vector Representation\n",
    "def encode_document(doc, vocabulary):\n",
    "    words = doc.split()\n",
    "    encoded_doc = []\n",
    "    \n",
    "    for word in words:\n",
    "        if word in vocabulary:\n",
    "            encoded_doc.append(create_one_hot_encoding(word, vocabulary))\n",
    "    \n",
    "    return np.array(encoded_doc)\n",
    "\n",
    "# Encode each document\n",
    "encoded_documents = []\n",
    "for i, doc in enumerate(documents):\n",
    "    encoded_doc = encode_document(doc, vocabulary)\n",
    "    encoded_documents.append(encoded_doc)\n",
    "    \n",
    "    print(f\"\\nDocument D{i+1} One-Hot Encoding:\")\n",
    "    print(encoded_doc)\n",
    "    print(f\"Shape: {encoded_doc.shape}\")\n",
    "\n",
    "# 6. Demonstrate OOV Handling\n",
    "def handle_oov_document(doc, vocabulary):\n",
    "    words = doc.split()\n",
    "    known_words = []\n",
    "    unknown_words = []\n",
    "    \n",
    "    for word in words:\n",
    "        if word in vocabulary:\n",
    "            known_words.append(word)\n",
    "        else:\n",
    "            unknown_words.append(word)\n",
    "    \n",
    "    return known_words, unknown_words\n",
    "\n",
    "# Example of handling OOV words\n",
    "print(\"\\n7. Handling Out-of-Vocabulary (OOV) Words:\")\n",
    "new_doc = \"hello campusx peoples\"\n",
    "known, unknown = handle_oov_document(new_doc, vocabulary)\n",
    "\n",
    "print(f\"New Document: '{new_doc}'\")\n",
    "print(f\"Known Words: {known}\")\n",
    "print(f\"Unknown Words (OOV): {unknown}\")\n",
    "\n",
    "# Try to encode the document with OOV words\n",
    "encoded_new_doc = encode_document(new_doc, vocabulary)\n",
    "print(\"\\nEncoded New Document (only known words are encoded):\")\n",
    "print(encoded_new_doc)\n",
    "print(f\"Shape: {encoded_new_doc.shape}\")\n",
    "\n",
    "# 8. Demonstrate Orthogonality - Calculate distances between word vectors\n",
    "print(\"\\n8. Demonstrating lack of semantic relationships:\")\n",
    "\n",
    "# Create a simple example with three words\n",
    "simple_vocabulary = [\"walk\", \"run\", \"shoe\"]\n",
    "simple_encodings = {}\n",
    "\n",
    "for word in simple_vocabulary:\n",
    "    vector = [0] * len(simple_vocabulary)\n",
    "    vector[simple_vocabulary.index(word)] = 1\n",
    "    simple_encodings[word] = vector\n",
    "\n",
    "print(\"Simple One-Hot Encodings:\")\n",
    "for word, vector in simple_encodings.items():\n",
    "    print(f\"{word}: {vector}\")\n",
    "\n",
    "# Calculate Euclidean distances between vectors\n",
    "def euclidean_distance(vec1, vec2):\n",
    "    return np.sqrt(sum((a - b) ** 2 for a, b in zip(vec1, vec2)))\n",
    "\n",
    "print(\"\\nEuclidean Distances:\")\n",
    "for word1 in simple_vocabulary:\n",
    "    for word2 in simple_vocabulary:\n",
    "        if word1 != word2:\n",
    "            dist = euclidean_distance(simple_encodings[word1], simple_encodings[word2])\n",
    "            print(f\"Distance between '{word1}' and '{word2}': {dist:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998b6aa2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
