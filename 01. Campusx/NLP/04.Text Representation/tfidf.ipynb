{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da31ef1c",
   "metadata": {},
   "source": [
    "### IDF: Measures how rare a word is across all documents. Rare words are more important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ea9dcc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Document 1 TF-IDF scores:\n",
      "sat: 1.0986\n",
      "on: 1.0986\n",
      "chased: 1.0986\n",
      "dog: 1.0986\n",
      "was: 1.0986\n",
      "there: 1.0986\n",
      "sitting: 1.0986\n",
      "cat: 0.4055\n",
      "mat: 0.4055\n",
      "the: 0.0000\n",
      "\n",
      "Document 2 TF-IDF scores:\n",
      "sat: 1.0986\n",
      "on: 1.0986\n",
      "chased: 1.0986\n",
      "dog: 1.0986\n",
      "was: 1.0986\n",
      "there: 1.0986\n",
      "sitting: 1.0986\n",
      "cat: 0.4055\n",
      "mat: 0.4055\n",
      "the: 0.0000\n",
      "\n",
      "Document 3 TF-IDF scores:\n",
      "sat: 1.0986\n",
      "on: 1.0986\n",
      "chased: 1.0986\n",
      "dog: 1.0986\n",
      "was: 1.0986\n",
      "there: 1.0986\n",
      "sitting: 1.0986\n",
      "cat: 0.4055\n",
      "mat: 0.4055\n",
      "the: 0.0000\n"
     ]
    }
   ],
   "source": [
    "import math \n",
    "from collections import Counter\n",
    "\n",
    "def calculate_term_frequency(document):\n",
    "    # Convert document to lowercase and split into words\n",
    "    words = document.lower().split()\n",
    "    # Count total words\n",
    "    total_words = len(words)\n",
    "    # Count frequency of each word\n",
    "    words_count = Counter(words)\n",
    "    # Calculate term frequency for each word\n",
    "    return {word: count/total_words for word, count in words_count.items()}\n",
    "\n",
    "def calculate_idf(documents):\n",
    "    # Total number of documents\n",
    "    N = len(documents)\n",
    "    # Count documents containing each word\n",
    "    word_doc_count = {}\n",
    "    for doc in documents:\n",
    "        unique_words = set(doc.lower().split())\n",
    "        for word in unique_words:\n",
    "            word_doc_count[word] = word_doc_count.get(word, 0) +1 \n",
    "    # calculate the IDF for each word \n",
    "    return {word: math.log(N/count) for word, count in word_doc_count.items()}\n",
    "\n",
    "\n",
    "def calculate_tfidf(documents):\n",
    "    # Calculate IDF scores\n",
    "    idf_scores = calculate_idf(documents=documents)\n",
    "    # Calculate TF-IDF for each document\n",
    "    tfidf_documents = []\n",
    "\n",
    "    for doc in documents:\n",
    "        # calculate the term frequency for current document\n",
    "        tf_scores = calculate_term_frequency(doc)\n",
    "        # Calcuate TF-IDF for each word \n",
    "        tfidf_score = {\n",
    "            word: tf * idf_scores[word]\n",
    "            for word, tf in tf_scores.items()\n",
    "        }\n",
    "        tfidf_documents.append(idf_scores)\n",
    "    \n",
    "    return tfidf_documents\n",
    "\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Sample documents\n",
    "    documents = [\n",
    "        \"The cat sat on the mat\",\n",
    "        \"The dog chased the cat\",\n",
    "        \"The mat was sitting there\"\n",
    "    ]\n",
    "    \n",
    "    # Calculate TF-IDF scores\n",
    "    tfidf_scores = calculate_tfidf(documents)\n",
    "    \n",
    "    # Print results\n",
    "    for i, doc_scores in enumerate(tfidf_scores):\n",
    "        print(f\"\\nDocument {i + 1} TF-IDF scores:\")\n",
    "        # Sort words by TF-IDF score in descending order\n",
    "        sorted_words = sorted(doc_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "        for word, score in sorted_words:\n",
    "            print(f\"{word}: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e9e973f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of unique words (vocabulary): ['campusx', 'comment', 'people', 'watch', 'write']\n",
      "Term Frequency for Document 1: {'campusx': 0.3333333333333333, 'comment': 0.0, 'people': 0.3333333333333333, 'watch': 0.3333333333333333, 'write': 0.0}\n",
      "Term Frequency for Document 2: {'campusx': 0.6666666666666666, 'comment': 0.0, 'people': 0.0, 'watch': 0.3333333333333333, 'write': 0.0}\n",
      "Term Frequency for Document 3: {'campusx': 0.0, 'comment': 0.3333333333333333, 'people': 0.3333333333333333, 'watch': 0.0, 'write': 0.3333333333333333}\n",
      "Term Frequency for Document 4: {'campusx': 0.3333333333333333, 'comment': 0.3333333333333333, 'people': 0.0, 'watch': 0.0, 'write': 0.3333333333333333}\n",
      "\n",
      "Inverse Document Frequency (IDF) scores: {'campusx': 0.28768207245178085, 'comment': 0.6931471805599453, 'people': 0.6931471805599453, 'watch': 0.6931471805599453, 'write': 0.6931471805599453}\n",
      "\n",
      "TF-IDF scores for Document 1: {'campusx': 0.09589402415059362, 'comment': 0.0, 'people': 0.23104906018664842, 'watch': 0.23104906018664842, 'write': 0.0}\n",
      "\n",
      "TF-IDF scores for Document 2: {'campusx': 0.19178804830118723, 'comment': 0.0, 'people': 0.0, 'watch': 0.23104906018664842, 'write': 0.0}\n",
      "\n",
      "TF-IDF scores for Document 3: {'campusx': 0.0, 'comment': 0.23104906018664842, 'people': 0.23104906018664842, 'watch': 0.0, 'write': 0.23104906018664842}\n",
      "\n",
      "TF-IDF scores for Document 4: {'campusx': 0.09589402415059362, 'comment': 0.23104906018664842, 'people': 0.0, 'watch': 0.0, 'write': 0.23104906018664842}\n",
      "\n",
      "TF-IDF Table:\n",
      "             campusx   comment    people     watch     write\n",
      "Document 1  0.095894  0.000000  0.231049  0.231049  0.000000\n",
      "Document 2  0.191788  0.000000  0.000000  0.231049  0.000000\n",
      "Document 3  0.000000  0.231049  0.231049  0.000000  0.231049\n",
      "Document 4  0.095894  0.231049  0.000000  0.000000  0.231049\n",
      "\n",
      "Document Vectors (TF-IDF scores):\n",
      "Document 1: [0.09589402415059362, 0.0, 0.23104906018664842, 0.23104906018664842, 0.0]\n",
      "Document 2: [0.19178804830118723, 0.0, 0.0, 0.23104906018664842, 0.0]\n",
      "Document 3: [0.0, 0.23104906018664842, 0.23104906018664842, 0.0, 0.23104906018664842]\n",
      "Document 4: [0.09589402415059362, 0.23104906018664842, 0.0, 0.0, 0.23104906018664842]\n",
      "\n",
      "Document Similarities (Cosine Similarity):\n",
      "Similarity between Document 1 and Document 2: 0.7019\n",
      "Similarity between Document 1 and Document 3: 0.3917\n",
      "Similarity between Document 1 and Document 4: 0.0793\n",
      "Similarity between Document 2 and Document 3: 0.0000\n",
      "Similarity between Document 2 and Document 4: 0.1799\n",
      "Similarity between Document 3 and Document 4: 0.7835\n"
     ]
    }
   ],
   "source": [
    "# Import libraries we need\n",
    "import numpy as np  # For math calculations\n",
    "import pandas as pd  # For creating a table to display results\n",
    "from collections import Counter  # To count words easily\n",
    "import math  # For logarithm function\n",
    "\n",
    "# Our sample text documents (like short sentences)\n",
    "text_documents = [\n",
    "    \"people watch campusx\",  # Document 1\n",
    "    \"campusx watch campusx\",  # Document 2\n",
    "    \"people write comment\",   # Document 3\n",
    "    \"campusx write comment\"   # Document 4\n",
    "]\n",
    "\n",
    "# Step 1: Create a list of all unique words (vocabulary)\n",
    "def build_word_list(documents):\n",
    "    # Create an empty set to store unique words (sets don't allow duplicates)\n",
    "    unique_words = set()\n",
    "    \n",
    "    # Go through each document\n",
    "    for doc in documents:\n",
    "        # Split the document into words (e.g., \"people watch\" -> [\"people\", \"watch\"])\n",
    "        words = doc.split()\n",
    "        # Add each word to the set\n",
    "        for word in words:\n",
    "            unique_words.add(word)\n",
    "    \n",
    "    # Convert set to a sorted list for consistency\n",
    "    word_list = sorted(list(unique_words))\n",
    "    return word_list\n",
    "\n",
    "# Create the vocabulary and print it\n",
    "vocabulary = build_word_list(text_documents)\n",
    "print(\"List of unique words (vocabulary):\", vocabulary)\n",
    "\n",
    "# Step 2: Calculate Term Frequency (TF)\n",
    "# TF = (Number of times a word appears in a document) / (Total words in that document)\n",
    "def calculate_term_frequency(document, word_list):\n",
    "    # Split document into words\n",
    "    words = document.split()\n",
    "    # Count how many times each word appears\n",
    "    word_counts = Counter(words)\n",
    "    # Total number of words in the document\n",
    "    total_words = len(words)\n",
    "    \n",
    "    # Create a dictionary to store TF values\n",
    "    tf_scores = {}\n",
    "    # Calculate TF for each word in the vocabulary\n",
    "    for word in word_list:\n",
    "        # If word isn't in document, Counter returns 0\n",
    "        tf_scores[word] = word_counts[word] / total_words\n",
    "    \n",
    "    return tf_scores\n",
    "\n",
    "# Calculate TF for each document\n",
    "term_frequency_list = []\n",
    "for doc_number, doc in enumerate(text_documents, 1):\n",
    "    tf_scores = calculate_term_frequency(doc, vocabulary)\n",
    "    term_frequency_list.append(tf_scores)\n",
    "    print(f\"Term Frequency for Document {doc_number}:\", tf_scores)\n",
    "\n",
    "# Step 3: Calculate Inverse Document Frequency (IDF)\n",
    "# IDF = log(Total number of documents / Number of documents containing the word)\n",
    "def calculate_inverse_document_frequency(documents, word_list):\n",
    "    # Total number of documents\n",
    "    total_documents = len(documents)\n",
    "    # Create a dictionary to store IDF values\n",
    "    idf_scores = {}\n",
    "    \n",
    "    # Calculate IDF for each word\n",
    "    for word in word_list:\n",
    "        # Count how many documents contain the word\n",
    "        documents_with_word = 0\n",
    "        for doc in documents:\n",
    "            if word in doc.split():\n",
    "                documents_with_word += 1\n",
    "        # Calculate IDF using the formula\n",
    "        idf_scores[word] = math.log(total_documents / documents_with_word)\n",
    "    \n",
    "    return idf_scores\n",
    "\n",
    "# Calculate IDF and print it\n",
    "idf_scores = calculate_inverse_document_frequency(text_documents, vocabulary)\n",
    "print(\"\\nInverse Document Frequency (IDF) scores:\", idf_scores)\n",
    "\n",
    "# Step 4: Calculate TF-IDF\n",
    "# TF-IDF = Term Frequency * Inverse Document Frequency\n",
    "def calculate_tf_idf(term_frequency_list, idf_scores):\n",
    "    tf_idf_scores_list = []\n",
    "    \n",
    "    # Go through each document's TF scores\n",
    "    for tf_scores in term_frequency_list:\n",
    "        tf_idf_scores = {}\n",
    "        # Multiply TF by IDF for each word\n",
    "        for word, tf_value in tf_scores.items():\n",
    "            tf_idf_scores[word] = tf_value * idf_scores[word]\n",
    "        tf_idf_scores_list.append(tf_idf_scores)\n",
    "    \n",
    "    return tf_idf_scores_list\n",
    "\n",
    "# Calculate TF-IDF\n",
    "tf_idf_scores_list = calculate_tf_idf(term_frequency_list, idf_scores)\n",
    "\n",
    "# Print TF-IDF for each document\n",
    "for doc_number, tf_idf_scores in enumerate(tf_idf_scores_list, 1):\n",
    "    print(f\"\\nTF-IDF scores for Document {doc_number}:\", tf_idf_scores)\n",
    "\n",
    "# Step 5: Create a matrix (table) of TF-IDF scores\n",
    "def create_tf_idf_table(tf_idf_scores_list, word_list):\n",
    "    tf_idf_table = []\n",
    "    \n",
    "    # Convert each document's TF-IDF scores into a list\n",
    "    for tf_idf_scores in tf_idf_scores_list:\n",
    "        document_vector = []\n",
    "        for word in word_list:\n",
    "            document_vector.append(tf_idf_scores[word])\n",
    "        tf_idf_table.append(document_vector)\n",
    "    \n",
    "    return tf_idf_table\n",
    "\n",
    "# Create the TF-IDF matrix\n",
    "tf_idf_table = create_tf_idf_table(tf_idf_scores_list, vocabulary)\n",
    "\n",
    "# Step 6: Display the TF-IDF matrix as a nice table\n",
    "tf_idf_dataframe = pd.DataFrame(tf_idf_table, columns=vocabulary)\n",
    "tf_idf_dataframe.index = [f\"Document {i+1}\" for i in range(len(text_documents))]\n",
    "print(\"\\nTF-IDF Table:\")\n",
    "print(tf_idf_dataframe)\n",
    "\n",
    "# Step 7: Show each document as a vector (list of numbers)\n",
    "print(\"\\nDocument Vectors (TF-IDF scores):\")\n",
    "for doc_number, vector in enumerate(tf_idf_table, 1):\n",
    "    print(f\"Document {doc_number}: {vector}\")\n",
    "\n",
    "# Step 8: Calculate Cosine Similarity to compare documents\n",
    "def calculate_cosine_similarity(vector1, vector2):\n",
    "    # Calculate dot product (multiply corresponding numbers and sum them)\n",
    "    dot_product = 0\n",
    "    for value1, value2 in zip(vector1, vector2):\n",
    "        dot_product += value1 * value2\n",
    "    \n",
    "    # Calculate the length (norm) of each vector\n",
    "    norm_vector1 = math.sqrt(sum(value * value for value in vector1))\n",
    "    norm_vector2 = math.sqrt(sum(value * value for value in vector2))\n",
    "    \n",
    "    # If either vector has zero length, similarity is 0\n",
    "    if norm_vector1 == 0 or norm_vector2 == 0:\n",
    "        return 0\n",
    "    \n",
    "    # Calculate cosine similarity\n",
    "    return dot_product / (norm_vector1 * norm_vector2)\n",
    "\n",
    "# Calculate and print similarities between all pairs of documents\n",
    "print(\"\\nDocument Similarities (Cosine Similarity):\")\n",
    "for i in range(len(text_documents)):\n",
    "    for j in range(i + 1, len(text_documents)):\n",
    "        similarity = calculate_cosine_similarity(tf_idf_table[i], tf_idf_table[j])\n",
    "        print(f\"Similarity between Document {i+1} and Document {j+1}: {similarity:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fdeadbf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
