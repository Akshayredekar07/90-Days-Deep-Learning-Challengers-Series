{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Load the image\n",
    "image = cv2.imread('mrunal1.png')\n",
    "\n",
    "# Define new dimensions\n",
    "new_width = 300\n",
    "new_height = 200\n",
    "new_dimensions = (new_width, new_height)\n",
    "\n",
    "# Resize the image\n",
    "resized_image = cv2.resize(image, new_dimensions, interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "# Save or display the resized image\n",
    "cv2.imwrite('resized_image.jpg', resized_image)\n",
    "cv2.imshow('Original Image', image)\n",
    "cv2.imshow('Resized Image', resized_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Load the image\n",
    "image = cv2.imread('flowers.jpg')\n",
    "\n",
    "# Define scale factors\n",
    "scale_x = 0.5  # Scale down to 50% of the original width\n",
    "scale_y = 0.5  # Scale down to 50% of the original height\n",
    "\n",
    "# Resize the image\n",
    "resized_image = cv2.resize(image, None, fx=scale_x, fy=scale_y, interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "# Save or display the resized image\n",
    "cv2.imwrite('resized_image_scaled.jpg', resized_image)\n",
    "cv2.imshow('Resized Image', resized_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maintaining Aspect Ratio\n",
    "import cv2\n",
    "\n",
    "# Load the image\n",
    "image = cv2.imread('sai1.png')\n",
    "\n",
    "# Get original dimensions\n",
    "original_height, original_width = image.shape[:2]\n",
    "\n",
    "# Desired width\n",
    "desired_width = 400\n",
    "\n",
    "# Calculate the aspect ratio\n",
    "aspect_ratio = original_height / original_width\n",
    "\n",
    "# Compute new dimensions\n",
    "new_width = desired_width\n",
    "new_height = int(desired_width * aspect_ratio)\n",
    "\n",
    "# Resize the image\n",
    "resized_image = cv2.resize(image, (new_width, new_height), interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "# Save or display the resized image\n",
    "# cv2.imwrite('resized_image_aspect_ratio.jpg', resized_image)\n",
    "cv2.imshow('Resized Image with Aspect Ratio', resized_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To rotate an image using OpenCV, it's essential to understand the underlying affine transformation process, which combines rotation and translation operations. Here's a structured breakdown:\n",
    "\n",
    "### Core Rotation Matrix\n",
    "\n",
    "In a 2D Cartesian coordinate system, rotating a point $(x, y)$ around the origin by an angle $\\theta$ counterclockwise is achieved using the rotation matrix:\n",
    "\n",
    "$$\n",
    "R = \\begin{bmatrix}\n",
    "\\cos\\theta & -\\sin\\theta \\\\\n",
    "\\sin\\theta & \\cos\\theta\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "This matrix, when multiplied with the coordinate vector of a point, yields the new coordinates after rotation.\n",
    "\n",
    "### Adjusting for Arbitrary Rotation Centers\n",
    "\n",
    "Images are typically rotated around their center rather than the origin. To rotate an image around a specific center point $(c_x, c_y)$, the transformation involves:\n",
    "\n",
    "1. **Translation to the Origin**: Shift the image so that the center of rotation aligns with the origin.\n",
    "2. **Rotation**: Apply the rotation matrix $R$.\n",
    "3. **Translation Back to Original Position**: Shift the image back to its original position.\n",
    "\n",
    "Combining these steps, the transformation matrix $M$ becomes:\n",
    "\n",
    "$$\n",
    "M = \\begin{bmatrix}\n",
    "\\cos\\theta & -\\sin\\theta & (1 - \\cos\\theta) \\cdot c_x + \\sin\\theta \\cdot c_y \\\\\n",
    "\\sin\\theta & \\cos\\theta & -\\sin\\theta \\cdot c_x + (1 - \\cos\\theta) \\cdot c_y\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "This matrix accounts for both rotation and the necessary translations to rotate around the desired center.\n",
    "\n",
    "### Bounding Box Calculation to Prevent Cropping\n",
    "\n",
    "Rotating an image can cause parts of it to be cropped if the output image dimensions are not adjusted. To ensure the entire rotated image fits within the frame, the new dimensions can be calculated as:\n",
    "\n",
    "$$\n",
    "\\text{new\\_width} = h \\cdot |\\sin\\theta| + w \\cdot |\\cos\\theta|\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{new\\_height} = h \\cdot |\\cos\\theta| + w \\cdot |\\sin\\theta|\n",
    "$$\n",
    "\n",
    "Where $w$ and $h$ are the original width and height of the image, respectively. This calculation ensures that the rotated image is fully contained within the new dimensions.\n",
    "\n",
    "### OpenCV Implementation\n",
    "\n",
    "OpenCV provides the `cv2.getRotationMatrix2D()` function, which simplifies the creation of the rotation matrix. The function's syntax is:\n",
    "\n",
    "$$\n",
    "M = \\text{cv2.getRotationMatrix2D}((c_x, c_y), \\theta, \\text{scale})\n",
    "$$\n",
    "\n",
    "Where:\n",
    "\n",
    "- $(c_x, c_y)$: Center of rotation.\n",
    "- $\\theta$: Rotation angle in degrees.\n",
    "- `scale`: Scaling factor.\n",
    "\n",
    "The resulting matrix $M$ is then used with `cv2.warpAffine()` to apply the rotation:\n",
    "\n",
    "$$\n",
    "\\text{rotated\\_image} = \\text{cv2.warpAffine}(\\text{image}, M, (\\text{new\\_width}, \\text{new\\_height}))\n",
    "$$\n",
    "\n",
    "This function applies the affine transformation defined by $M$ to the image, producing the rotated output.\n",
    "\n",
    "Understanding these mathematical foundations allows for precise control over image rotation, ensuring that transformations are performed as intended without unintended cropping or distortion. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load image\n",
    "image = cv2.imread(\"image.png\")  # Change path as needed\n",
    "(h, w) = image.shape[:2]  # Get height and width\n",
    "\n",
    "angle = 30  # Rotation angle\n",
    "center = (w // 2, h // 2)  # Find center of image\n",
    "\n",
    "# Get the rotation matrix\n",
    "M = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "\n",
    "# Compute new bounding box size to prevent cropping\n",
    "cos_theta = np.abs(M[0, 0])  # cos(theta)\n",
    "sin_theta = np.abs(M[0, 1])  # sin(theta)\n",
    "\n",
    "new_w = int((h * sin_theta) + (w * cos_theta))\n",
    "new_h = int((h * cos_theta) + (w * sin_theta))\n",
    "\n",
    "# Adjust the rotation matrix to consider translation\n",
    "M[0, 2] += (new_w / 2) - center[0]\n",
    "M[1, 2] += (new_h / 2) - center[1]\n",
    "\n",
    "# Apply rotation\n",
    "rotated = cv2.warpAffine(image, M, (new_w, new_h))\n",
    "\n",
    "# Resize rotated image to match original height\n",
    "rotated_resized = cv2.resize(rotated, (w, h))  # Resize to original width and height\n",
    "\n",
    "# Show result\n",
    "hstacked = np.hstack([image, rotated_resized])\n",
    "cv2.imshow(\"Rotated Image\", hstacked)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Blur Image**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Blurring Techniques\n",
    "\n",
    "Image blurring is a fundamental image processing technique used for various purposes, including noise reduction, detail smoothing, and creating special effects. Here are three common blurring methods:\n",
    "\n",
    "**1. Gaussian Blurring:**\n",
    "\n",
    "* **Definition:** Gaussian blur is achieved by convolving an image with a Gaussian function (a bell-shaped curve).\n",
    "* **Purpose:**\n",
    "    * Reduces image noise.\n",
    "    * Smooths out details.\n",
    "    * Used as a preprocessing step in machine learning and deep learning models.\n",
    "* **Mechanism:** Each pixel's value is replaced by a weighted average of its neighboring pixels, where the weights are determined by a Gaussian distribution.\n",
    "\n",
    "**2. Median Blurring:**\n",
    "\n",
    "* **Definition:** Median blur uses a median filter, a non-linear digital filtering technique.\n",
    "* **Purpose:**\n",
    "    * Removes noise, especially \"salt and pepper\" noise (random black and white pixels).\n",
    "    * Preserves edges better than Gaussian blur under certain conditions.\n",
    "* **Mechanism:** Each pixel's value is replaced by the median value of its neighboring pixels.\n",
    "\n",
    "**3. Bilateral Blurring:**\n",
    "\n",
    "* **Definition:** Bilateral filtering is a non-linear, edge-preserving, and noise-reducing smoothing filter.\n",
    "* **Purpose:**\n",
    "    * Reduces noise while preserving sharp edges.\n",
    "    * Smooths details without blurring prominent features.\n",
    "* **Mechanism:**\n",
    "    * Replaces each pixel's intensity with a weighted average of its neighboring pixels.\n",
    "    * The weights consider both the spatial distance between pixels and the difference in their intensity values.\n",
    "    * Weights can be based on a Gaussian distribution.\n",
    "    * This ensures that pixels with similar intensities have a stronger influence on each other, preserving edges.\n",
    "\n",
    "\n",
    "**Key Considerations:**\n",
    "\n",
    "* **Kernel Size:** The size of the kernel (the neighborhood of pixels used for averaging) affects the degree of blurring. Larger kernels result in more significant blurring.\n",
    "* **Noise Type:** Different blurring methods are more effective for specific types of noise. Median blur is excellent for salt and pepper noise, while Gaussian blur is better for Gaussian noise.\n",
    "* **Edge Preservation:** Bilateral blur is designed to preserve edges, making it suitable for applications where detail retention is crucial.\n",
    "\n",
    "**Applications:**\n",
    "\n",
    "* **Image Editing:** Smoothing skin, reducing blemishes, creating depth of field effects.\n",
    "* **Computer Vision:** Preprocessing images for feature extraction, noise reduction before object detection.\n",
    "* **Medical Imaging:** Noise reduction in medical scans.\n",
    "* **Astronomy:** Reducing atmospheric noise in astronomical images.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "image = cv2.imread(\"mrunal1.png\")  \n",
    "gaussian_blur = cv2.GaussianBlur(image, (5, 5), 0)\n",
    "\n",
    "cv2.imshow(\"Gaussian Blurred Image\", gaussian_blur)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(\"image.png\")  \n",
    "median_blur = cv2.medianBlur(image, 5)\n",
    "\n",
    "cv2.imshow(\"Median Blurred Image\", median_blur)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(\"image.png\")  \n",
    "bilateral_blur = cv2.bilateralFilter(image, d=9, sigmaColor=75, sigmaSpace=75)\n",
    "\n",
    "cv2.imshow(\"Bilateral Blurred Image\", bilateral_blur)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load the original image\n",
    "image = cv2.imread(\"girl.jpg\")  # Change this to your actual image path\n",
    "\n",
    "# Ensure the image was loaded successfully\n",
    "if image is None:\n",
    "    raise ValueError(\"Image not found. Please check the file path.\")\n",
    "\n",
    "# Apply different blurring techniques\n",
    "average_blur = cv2.blur(image, (5, 5))  # Averaging Blur\n",
    "gaussian_blur = cv2.GaussianBlur(image, (5, 5), 0)  # Gaussian Blur\n",
    "median_blur = cv2.medianBlur(image, 5)  # Median Blur\n",
    "\n",
    "# Resize the original image to make it smaller if it's too large\n",
    "max_height = 300\n",
    "aspect_ratio = image.shape[1] / image.shape[0]\n",
    "new_width = int(max_height * aspect_ratio)\n",
    "\n",
    "# Resize all images to the same dimensions\n",
    "image = cv2.resize(image, (new_width, max_height))\n",
    "average_blur = cv2.resize(average_blur, (new_width, max_height))\n",
    "gaussian_blur = cv2.resize(gaussian_blur, (new_width, max_height))\n",
    "median_blur = cv2.resize(median_blur, (new_width, max_height))\n",
    "\n",
    "# Create labels for each image\n",
    "def add_label(img, label):\n",
    "    h, w = img.shape[:2]\n",
    "    result = img.copy()\n",
    "    cv2.putText(result, label, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)\n",
    "    return result\n",
    "\n",
    "image = add_label(image, \"Original\")\n",
    "average_blur = add_label(average_blur, \"Average Blur\")\n",
    "gaussian_blur = add_label(gaussian_blur, \"Gaussian Blur\")\n",
    "median_blur = add_label(median_blur, \"Median Blur\")\n",
    "\n",
    "# Create a 2x2 grid layout\n",
    "top_row = np.hstack([image, average_blur])\n",
    "bottom_row = np.hstack([gaussian_blur, median_blur])\n",
    "grid_display = np.vstack([top_row, bottom_row])\n",
    "\n",
    "# Show the combined image\n",
    "cv2.imshow(\"Blurring Techniques - 2x2 Grid\", grid_display)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Save image**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('girl.jpg')\n",
    "re_img = cv2.resize(img, (300, 450))\n",
    "\n",
    "h = np.hstack((re_img, re_img))\n",
    "\n",
    "cv2.imwrite(\"new_girl.png\",h)\n",
    "\n",
    "cv2.imshow(\"Img\", h)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MakeBorder using OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Read image\n",
    "img = cv2.imread('boy.jpg')\n",
    "\n",
    "# Define border size\n",
    "border_size = 50  # Big border (Increase for a bolder effect)\n",
    "\n",
    "# Add a thick red border\n",
    "img1 = cv2.copyMakeBorder(src=img, \n",
    "                          top=border_size, \n",
    "                          bottom=border_size, \n",
    "                          left=border_size, \n",
    "                          right=border_size, \n",
    "                          borderType=cv2.BORDER_CONSTANT,\n",
    "                          value=(0, 0, 255))  # Red border (BGR format)\n",
    "\n",
    "# Resize both images to match dimensions (keep aspect ratio)\n",
    "height = 500  # Fixed height\n",
    "width = 300   # Fixed width\n",
    "img_resized = cv2.resize(img, (width, height))\n",
    "img1_resized = cv2.resize(img1, (width, height))\n",
    "\n",
    "# Stack side by side\n",
    "hstack_img = np.hstack((img_resized, img1_resized))\n",
    "\n",
    "# Show the stacked images\n",
    "cv2.imshow(\"Original vs Bold Red Bordered\", hstack_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Read image\n",
    "img = cv2.imread('boy.jpg')\n",
    "\n",
    "# Define different border sizes\n",
    "thin_border = 10   # Small border (default)\n",
    "medium_border = 50  # Medium bold border\n",
    "thick_border = 100  # Very thick border\n",
    "\n",
    "# Apply borders\n",
    "img_thin = cv2.copyMakeBorder(img, thin_border, thin_border, thin_border, thin_border, cv2.BORDER_CONSTANT, value=(255, 255, 255))  # White border\n",
    "img_medium = cv2.copyMakeBorder(img, medium_border, medium_border, medium_border, medium_border, cv2.BORDER_CONSTANT, value=(0, 0, 255))  # Medium Red border\n",
    "img_thick = cv2.copyMakeBorder(img, thick_border, thick_border, thick_border, thick_border, cv2.BORDER_CONSTANT, value=(0, 0, 255))  # Thick Red border\n",
    "\n",
    "# Resize all images to be the same size (for stacking)\n",
    "width, height = 300, 500\n",
    "img_resized = cv2.resize(img, (width, height))\n",
    "img_thin_resized = cv2.resize(img_thin, (width, height))\n",
    "img_medium_resized = cv2.resize(img_medium, (width, height))\n",
    "img_thick_resized = cv2.resize(img_thick, (width, height))\n",
    "\n",
    "# Stack all images side by side\n",
    "hstack_img = np.hstack((img_resized, img_thin_resized, img_medium_resized, img_thick_resized))\n",
    "\n",
    "# Show the stacked images\n",
    "cv2.imshow(\"Original | Thin Border | Medium Red Border | Thick Red Border\", hstack_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Read image\n",
    "img = cv2.imread('flower.jpg')\n",
    "\n",
    "# Define different border sizes\n",
    "thin_border = 10\n",
    "medium_border = 50\n",
    "thick_border = 100\n",
    "\n",
    "# Apply different border types\n",
    "img_reflect = cv2.copyMakeBorder(img, thin_border, thin_border, thin_border, thin_border, cv2.BORDER_REFLECT)  # Reflect border\n",
    "img_wrap = cv2.copyMakeBorder(img, medium_border, medium_border, medium_border, medium_border, cv2.BORDER_WRAP)  # Wrap border\n",
    "img_replicate = cv2.copyMakeBorder(img, thick_border, thick_border, thick_border, thick_border, cv2.BORDER_REPLICATE)  # Replicate border\n",
    "img_dark = cv2.copyMakeBorder(img, thick_border, thick_border, thick_border, thick_border, cv2.BORDER_CONSTANT, value=(0, 0, 0))  # Dark black border\n",
    "\n",
    "# Resize all images to the same size for proper stacking\n",
    "width, height = 300, 500\n",
    "img_resized = cv2.resize(img, (width, height))\n",
    "img_reflect_resized = cv2.resize(img_reflect, (width, height))\n",
    "img_wrap_resized = cv2.resize(img_wrap, (width, height))\n",
    "img_replicate_resized = cv2.resize(img_replicate, (width, height))\n",
    "img_dark_resized = cv2.resize(img_dark, (width, height))\n",
    "\n",
    "# Stack all images side by side\n",
    "hstack_img = np.hstack((img_resized, img_reflect_resized, img_wrap_resized, img_replicate_resized, img_dark_resized))\n",
    "\n",
    "# Show the stacked images\n",
    "cv2.imshow(\"Original | Reflect | Wrap | Replicate | Dark Border\", hstack_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
