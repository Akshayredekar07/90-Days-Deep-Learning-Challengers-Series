{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install opencv-python\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('mrunal.png')  # Changed extension from jpg to png\n",
    "if img is not None:\n",
    "    # Display the image in a window titled 'First Image'\n",
    "    cv2.imshow('First Image', img)\n",
    "    \n",
    "    # Wait for 2 seconds\n",
    "    cv2.waitKey(2000)  # wait for 2000 milliseconds\n",
    "    \n",
    "    # Close all OpenCV windows\n",
    "    cv2.destroyAllWindows()\n",
    "else:\n",
    "    print(\"Error: Could not load the image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error\n"
     ]
    }
   ],
   "source": [
    "# img = cv2.imread('2.jpg')\n",
    "img = cv2.imread('4.jpg')  # corrected extension\n",
    "if img is not None:\n",
    "\tcv2.imshow('First Image', img)\n",
    "\tcv2.imshow('Second Image', img)\n",
    "\tcv2.waitKey(0)\n",
    "\tcv2.destroyAllWindows()\n",
    "else:\n",
    "\tprint(\"Error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img=cv2.imread('mrunal.png')\n",
    "cv2.imshow('Actress', img)\n",
    "# cv2.imshow('Actress', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyWindow('Actress')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How to resize the image \n",
    "img=cv2.imread('mrunal.png')\n",
    "# resize_img=cv2.resize(img, (300, 500))\n",
    "resize_img=cv2.resize(img, (400, 500))\n",
    "cv2.imshow('Actress', resize_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyWindow('Actress')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3, 1, 2, 3],\n",
       "       [1, 2, 3, 1, 2, 3]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = np.array([[1,2,3,1,2,3], [1,2,3,1,2,3]])\n",
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[110 104 116]\n",
      "  [110 104 116]\n",
      "  [110 104 116]\n",
      "  ...\n",
      "  [120 116 116]\n",
      "  [126 120 118]\n",
      "  [129 124 120]]\n",
      "\n",
      " [[110 104 116]\n",
      "  [110 104 116]\n",
      "  [110 104 116]\n",
      "  ...\n",
      "  [120 116 116]\n",
      "  [126 120 118]\n",
      "  [129 124 120]]\n",
      "\n",
      " [[110 104 116]\n",
      "  [110 104 116]\n",
      "  [110 104 116]\n",
      "  ...\n",
      "  [119 114 115]\n",
      "  [126 120 118]\n",
      "  [129 124 120]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 82  70  72]\n",
      "  [ 82  70  72]\n",
      "  [ 85  73  75]\n",
      "  ...\n",
      "  [ 66  61  62]\n",
      "  [ 66  61  62]\n",
      "  [ 66  61  62]]\n",
      "\n",
      " [[ 83  71  73]\n",
      "  [ 83  71  73]\n",
      "  [ 85  73  75]\n",
      "  ...\n",
      "  [ 69  64  65]\n",
      "  [ 69  64  65]\n",
      "  [ 69  64  65]]\n",
      "\n",
      " [[ 83  71  73]\n",
      "  [ 83  71  73]\n",
      "  [ 85  73  75]\n",
      "  ...\n",
      "  [ 70  66  66]\n",
      "  [ 70  66  66]\n",
      "  [ 70  66  66]]]\n"
     ]
    }
   ],
   "source": [
    "img=cv2.imread('mrunal.png')\n",
    "print(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 800, 3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Resize image to 300x500 pixels and save it\n",
    "resized = cv2.resize(img, (300, 500))\n",
    "cv2.imwrite('resized_mrunal.png', resized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_sai = cv2.imread('sai.png')\n",
    "if img_sai is not None:\n",
    "    resized_sai = cv2.resize(img_sai, (300, 500))\n",
    "    cv2.imshow('Original Sai', img_sai)\n",
    "    cv2.imshow('Resized Sai', resized_sai)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "else:\n",
    "    print(\"Error: Could not load sai.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = np.array([1,2,3,1,2,3])\n",
    "np.hstack((v,v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_sai = cv2.imread('sai.png')\n",
    "resized_sai = cv2.resize(img_sai, (300, 500))\n",
    "horizontal_ = np.hstack((resized_sai, resized_sai))\n",
    "cv2.imshow('Resized Sai', horizontal_)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_sai = cv2.imread('sai.png')\n",
    "resized_sai = cv2.resize(img_sai, (300, 500))\n",
    "vertical_ = np.vstack((resized_sai, resized_sai))\n",
    "cv2.imshow('Resized Sai', vertical_)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_sai = cv2.imread('sai.png')\n",
    "resized_sai = cv2.resize(img_sai, (300, 500))\n",
    "horizontal_ = np.hstack((resized_sai, resized_sai, resized_sai))\n",
    "vertical_ = np.vstack((horizontal_, horizontal_))\n",
    "cv2.imshow('Resized Sai', vertical_)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_sai = cv2.imread('sai.png')\n",
    "resized_sai = cv2.resize(img_sai, (300, 500))\n",
    "horizontal_ = np.hstack((resized_sai, resized_sai, resized_sai))\n",
    "vertical_ = np.vstack((horizontal_, horizontal_))\n",
    "cv2.imshow('Resized Sai', vertical_)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Slide `show()`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "name_list=os.listdir(\"D:\\\\DEEP LEARNING\\\\Computer Vision\\\\wscube\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['01.introduction.ipynb',\n",
       " '02-Video.ipynb',\n",
       " 'jaspreet.png',\n",
       " 'mrunal.png',\n",
       " 'mrunal1.png',\n",
       " 'ram.png',\n",
       " 'resized_mrunal.png',\n",
       " 'rohit.png',\n",
       " 'sai.png',\n",
       " 'sai1.png',\n",
       " 'sharma.png']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not read image: 01.introduction.ipynb\n",
      "Could not read image: 02-Video.ipynb\n"
     ]
    }
   ],
   "source": [
    "for name in name_list:\n",
    "    path=\"D:\\\\DEEP LEARNING\\\\Computer Vision\\\\wscube\"\n",
    "    img_name=path+\"\\\\\"+name\n",
    "    img=cv2.imread(img_name)\n",
    "    if img is not None:\n",
    "        resized_img = cv2.resize(img, (500, 700))\n",
    "        cv2.imshow('Test Imgs', resized_img)\n",
    "        cv2.waitKey(2000)\n",
    "        cv2.destroyAllWindows()\n",
    "    else:\n",
    "        print(f\"Could not read image: {name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not read image: 01.introduction.ipynb\n",
      "Could not read image: 02-Video.ipynb\n"
     ]
    }
   ],
   "source": [
    "for name in name_list:\n",
    "    path=\"D:\\\\DEEP LEARNING\\\\Computer Vision\\\\wscube\"\n",
    "    img_name=path+\"\\\\\"+name\n",
    "    img=cv2.imread(img_name)\n",
    "    if img is not None:\n",
    "        resized_img = cv2.resize(img, (500, 700))\n",
    "        cv2.imshow('Test Imgs', resized_img)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "    else:\n",
    "        print(f\"Could not read image: {name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(375, 500, 3)\n"
     ]
    }
   ],
   "source": [
    "# import cv2 \n",
    "img=cv2.imread('jaspreet.png')\n",
    "# print(img)\n",
    "print(img.shape)\n",
    "img=cv2.resize(img, (500, 500))\n",
    "cv2.imshow(\"Jaspreet\", img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Image Reading Flags in OpenCV**\n",
    "\n",
    "- **1 or `cv2.IMREAD_COLOR`**: Loads color image (default)\n",
    "- **0 or `cv2.IMREAD_GRAYSCALE`**: Loads image in grayscale\n",
    "- **-1 or `cv2.IMREAD_UNCHANGED`**: Loads image as-is with alpha channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(375, 500, 3)\n"
     ]
    }
   ],
   "source": [
    "# import cv2 \n",
    "img=cv2.imread('jaspreet.png', 1)\n",
    "print(img.shape)\n",
    "img=cv2.resize(img, (500, 500))\n",
    "cv2.imshow(\"Jaspreet\", img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1080, 1080, 3)\n"
     ]
    }
   ],
   "source": [
    "img = cv2.imread('roko.jpg', 0)  # BGR  (0-255)\n",
    "img = cv2.imread('roko.jpg', -1)  # BGR  (0-255)\n",
    "img = cv2.imread('roko.jpg', 1)  # BGR  (0-255)\n",
    "if img is not None:\n",
    "\tprint(img.shape)\n",
    "\timg = cv2.resize(img, (500, 500))\n",
    "\tcv2.imshow(\"allu\", img)\n",
    "\tcv2.waitKey(0)\n",
    "\tcv2.destroyAllWindows()\n",
    "else:\n",
    "\tprint(\"Error: Could not load allu.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 500, 3)\n"
     ]
    }
   ],
   "source": [
    "# import cv2 \n",
    "img=cv2.imread('ram.png', -1)\n",
    "print(img.shape)\n",
    "img=cv2.resize(img, (500, 500))\n",
    "cv2.imshow(\"ram\", img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BGR to RGB Conversion Done\n"
     ]
    }
   ],
   "source": [
    "## useful for Deep Learning\n",
    "import cv2\n",
    "\n",
    "img = cv2.imread('allu.png')  # Default is BGR\n",
    "if img is not None:\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert to RGB\n",
    "    print(\"BGR to RGB Conversion Done\")\n",
    "    cv2.imshow(\"RGB Image\", img_rgb)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "else:\n",
    "    print(\"Error: Could not load allu.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channels Split and Merged Successfully\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "img = cv2.imread('rohit.png')  # Load in BGR format\n",
    "if img is not None:\n",
    "    b, g, r = cv2.split(img)  # Extract individual color channels\n",
    "    merged = cv2.merge([b, g, r])  # Merge them back\n",
    "    print(\"Channels Split and Merged Successfully\")\n",
    "    cv2.imshow(\"Merged Image\", merged)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "else:\n",
    "    print(\"Error: Could not load rohit.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Parameters for `cv2.putText()`**\n",
    "\n",
    "#### **Text Position (`org`)**\n",
    "- Uses (x,y) coordinates\n",
    "- Example: (50,100) means:\n",
    "    - 50 pixels from left\n",
    "    - 100 pixels from top\n",
    "\n",
    "#### **Font Style (`fontFace`)**\n",
    "- `FONT_HERSHEY_SIMPLEX`: Basic font\n",
    "- `FONT_HERSHEY_PLAIN`: Simple thin font  \n",
    "- `FONT_HERSHEY_DUPLEX`: Thicker font\n",
    "- `FONT_HERSHEY_COMPLEX`: More stylized font\n",
    "- And more...\n",
    "\n",
    "#### **Color**\n",
    "- Uses (Blue, Green, Red) values \n",
    "- Each color ranges 0-255\n",
    "- Example: `(255,0,0)` is bright blue\n",
    "\n",
    "#### **Line Style (`lineType`)**\n",
    "- `FILLED (-1)`: Solid filled text\n",
    "- `LINE_4 (4)`: Basic lines\n",
    "- `LINE_8 (8)`: Smoother lines\n",
    "- `LINE_AA (16)`: Smoothest lines\n",
    "\n",
    "#### **Origin Point (`bottomLeftOrigin`)**\n",
    "- `False`: Start from top-left (default)\n",
    "- `True`: Start from bottom-left\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Image**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a blank image\n",
    "img = np.zeros((500, 800, 3), dtype=np.uint8)\n",
    "\n",
    "# Add text to the image\n",
    "cv2.putText(img, \"Hello OpenCV!\", (50, 200), cv2.FONT_HERSHEY_SIMPLEX, \n",
    "            2, (255, 0, 0), 3, cv2.LINE_AA)\n",
    "\n",
    "# Display the image\n",
    "cv2.imshow(\"Image with Text\", img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Create a blank white image\n",
    "image = np.ones((400, 600, 3), dtype=np.uint8) * 255\n",
    "\n",
    "# Define the text and its properties\n",
    "text = \"OpenCV Example\"\n",
    "org = (50, 200)  # Bottom-left corner of the text\n",
    "fontFace = cv2.FONT_HERSHEY_SIMPLEX\n",
    "fontScale = 1.5\n",
    "color = (0, 0, 255)  # Red color in BGR\n",
    "thickness = 2\n",
    "lineType = cv2.LINE_AA\n",
    "\n",
    "# Add text to the image\n",
    "cv2.putText(image, text, org, fontFace, fontScale, color, thickness, lineType)\n",
    "\n",
    "# Display the image\n",
    "cv2.imshow('Image with Text', image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_get = cv2.imread('mrunal1.png') \n",
    "img_get = cv2.resize(img_get, (500, 500))\n",
    "\n",
    "img = img_get # Copy the resized image to work with\n",
    "text = \"Mrunal\" # Text to be displayed on the image\n",
    "org = (50, 100) # Position coordinates (x=50, y=100 from top-left)\n",
    "fontFace = cv2.FONT_HERSHEY_DUPLEX  # Font style - thicker than SIMPLEX\n",
    "fontScale = 3 # Size of the text (larger number = bigger text)\n",
    "color = (0, 0, 255) # BGR color format - Red color (0 Blue, 0 Green, 255 Red)\n",
    "thickness = 3 # Thickness of the text lines\n",
    "lineType = cv2.LINE_8 # Line type for smoother text edges\n",
    "bottomLeftOrigin = False # If True, origin point starts from bottom-left; False means top-left\n",
    "\n",
    "cv2.putText(img, text, org, fontFace, fontScale, color, thickness, lineType, bottomLeftOrigin)\n",
    "\n",
    "\n",
    "cv2.imshow(\"Mrunal\", img_get)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Mrunal\"\n",
    "org1 = (50, 100)  # First text position\n",
    "org2 = (50, 200)  # Second text position, increased y-coordinate to place it below\n",
    "\n",
    "# First text\n",
    "cv2.putText(img, text, org1, fontFace, fontScale, color, thickness, lineType, bottomLeftOrigin)\n",
    "# Second text\n",
    "cv2.putText(img, text, org2, fontFace, fontScale, color, thickness, lineType, bottomLeftOrigin)\n",
    "\n",
    "cv2.imshow(\"Mrunal\", img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Bounding Boxes**\n",
    "- Used to highlight or mark regions of interest in images\n",
    "- Common drawing functions:\n",
    "    - `cv2.rectangle()`: Draw rectangular boxes\n",
    "    - `cv2.circle()`: Draw circular boundaries \n",
    "    - `cv2.line()`: Draw line segments\n",
    "    - `cv2.ellipse()`: Draw elliptical shapes\n",
    "- Key parameters:\n",
    "    - Image matrix\n",
    "    - Start coordinates (x1,y1)\n",
    "    - End coordinates (x2,y2) \n",
    "    - Color in BGR format\n",
    "    - Thickness (-1 for filled shape)\n",
    "    - Line type (4/8/16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Line on image**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "img=cv2.imread('sai.png')\n",
    "img=cv2.resize(img, (300, 500))\n",
    "# Add line\n",
    "new_img=cv2.line(img=img, pt1=(130, 40), pt2=(200, 40), color=(0,255,0), thickness=2, lineType=4)\n",
    "cv2.imshow(\"Sai\", new_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Load and resize the image\n",
    "img = cv2.imread('sai.png')\n",
    "if img is not None:\n",
    "    img = cv2.resize(img, (300, 500))\n",
    "\n",
    "    # Draw a green line\n",
    "    cv2.line(img, pt1=(50, 50), pt2=(250, 50), color=(0, 255, 0), thickness=2, lineType=cv2.LINE_8)\n",
    "\n",
    "    # Display the image with shapes\n",
    "    cv2.imshow(\"Bounding Box Example\", img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "else:\n",
    "    print(\"Error: Could not load sai.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Rectangle**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "img=cv2.imread('sai.png')\n",
    "img=cv2.resize(img, (300, 500))\n",
    "# Add line\n",
    "new_img=cv2.rectangle(img=img, pt1=(130, 35), pt2=(200, 120), color=(0,255,0), thickness=2, lineType=4)\n",
    "cv2.imshow(\"Sai\", new_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "text with rectangle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "img=cv2.imread('sai.png')\n",
    "img=cv2.resize(img, (300, 500))\n",
    "# Add rectangle\n",
    "new_img=cv2.rectangle(img=img, pt1=(130, 35), pt2=(200, 120), color=(0,255,0), thickness=2, lineType=4)\n",
    "# Add text inside rectangle\n",
    "text = \"SAI\"\n",
    "cv2.putText(new_img, text, (150, 140), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,255,0), 2, lineType)\n",
    "cv2.imshow(\"Sai\", new_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Circle on image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "img=cv2.imread('mrunal.png')\n",
    "img=cv2.resize(img, (500, 700))\n",
    "center_coordinates = (220, 150) \n",
    "radius = 80\n",
    "color = (0,255,0) \n",
    "thickness = 4\n",
    "# thickness = -1\n",
    "image = cv2.circle(img, center_coordinates, radius, color, thickness)\n",
    "cv2.imshow(\"Mrunal\", image) \n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ellipse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import cv2\n",
    "img=cv2.imread('sai.png')\n",
    "img=cv2.resize(img, (500, 700))\n",
    "image = cv2.ellipse(img=img, center=(270, 130), axes=(60, 50), angle=60, startAngle=0, endAngle=360, color=(0, 255, 0), thickness=4, lineType=16)\n",
    "cv2.imshow(\"Sai\", image) \n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np   \n",
    "Img = np.zeros((512, 512, 3), np.uint8)   \n",
    "window_name = 'Image'  \n",
    "center_coordinates = (220, 150)  \n",
    "radius, color, thickness = 100, (255, 133, 233), -1  \n",
    "\n",
    "image = cv2.circle(Img, center_coordinates, radius, color, thickness)   \n",
    "cv2.imshow(window_name, image)   \n",
    "cv2.waitKey(0)   \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Load and resize the image\n",
    "img = cv2.imread('flowers.jpg')\n",
    "if img is not None:\n",
    "    img = cv2.resize(img, (300, 500))\n",
    "\n",
    "    # Draw a green line\n",
    "    cv2.line(img, (50, 50), (250, 50), (0, 255, 0), thickness=2, lineType=cv2.LINE_8)\n",
    "\n",
    "    # Draw a red rectangle\n",
    "    cv2.rectangle(img, (50, 100), (250, 300), (0, 0, 255), thickness=3)\n",
    "\n",
    "    # Draw a blue circle\n",
    "    cv2.circle(img, (150, 400), 40, (255, 0, 0), thickness=-1)\n",
    "\n",
    "    # Draw a yellow ellipse\n",
    "    cv2.ellipse(img, (150, 200), (80, 50), 0, 0, 180, (255, 255, 0), thickness=2)\n",
    "\n",
    "    # Display the image with shapes\n",
    "    cv2.imshow(\"Bounding Box Example\", img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "else:\n",
    "    print(\"Error: Could not load sai.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
