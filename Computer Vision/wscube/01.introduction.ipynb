{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('1.jpg')\n",
    "# Display the image in a window titled 'First Image'\n",
    "cv2.imshow('First Image', img)\n",
    "\n",
    "# Wait for 2 seconds\n",
    "cv2.waitKey(2000)  # wait for 2000 milliseconds\n",
    "# cv2.waitKey(0)     # wait forever until key press \n",
    "\n",
    "# Close the specific window with title 'First Image'\n",
    "# cv2.destroyWindow('First Image')\n",
    "# Close all OpenCV windows that are currently open\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img = cv2.imread('2.jpg')\n",
    "img = cv2.imread('4.jpg')  # corrected extension\n",
    "if img is not None:\n",
    "\tcv2.imshow('First Image', img)\n",
    "\tcv2.imshow('Second Image', img)\n",
    "\tcv2.waitKey(0)\n",
    "\tcv2.destroyAllWindows()\n",
    "else:\n",
    "\tprint(\"Error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "img=cv2.imread('mrunal.png')\n",
    "cv2.imshow('Actress', img)\n",
    "cv2.imshow('Actress', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyWindow('Actress')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How to resize the image \n",
    "img=cv2.imread('mrunal.png')\n",
    "resize_img=cv2.resize(img, (300, 500))\n",
    "cv2.imshow('Actress', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyWindow('Actress')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3, 1, 2, 3],\n",
       "       [1, 2, 3, 1, 2, 3]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = np.array([[1,2,3,1,2,3], [1,2,3,1,2,3]])\n",
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[110 104 116]\n",
      "  [110 104 116]\n",
      "  [110 104 116]\n",
      "  ...\n",
      "  [120 116 116]\n",
      "  [126 120 118]\n",
      "  [129 124 120]]\n",
      "\n",
      " [[110 104 116]\n",
      "  [110 104 116]\n",
      "  [110 104 116]\n",
      "  ...\n",
      "  [120 116 116]\n",
      "  [126 120 118]\n",
      "  [129 124 120]]\n",
      "\n",
      " [[110 104 116]\n",
      "  [110 104 116]\n",
      "  [110 104 116]\n",
      "  ...\n",
      "  [119 114 115]\n",
      "  [126 120 118]\n",
      "  [129 124 120]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 82  70  72]\n",
      "  [ 82  70  72]\n",
      "  [ 85  73  75]\n",
      "  ...\n",
      "  [ 66  61  62]\n",
      "  [ 66  61  62]\n",
      "  [ 66  61  62]]\n",
      "\n",
      " [[ 83  71  73]\n",
      "  [ 83  71  73]\n",
      "  [ 85  73  75]\n",
      "  ...\n",
      "  [ 69  64  65]\n",
      "  [ 69  64  65]\n",
      "  [ 69  64  65]]\n",
      "\n",
      " [[ 83  71  73]\n",
      "  [ 83  71  73]\n",
      "  [ 85  73  75]\n",
      "  ...\n",
      "  [ 70  66  66]\n",
      "  [ 70  66  66]\n",
      "  [ 70  66  66]]]\n"
     ]
    }
   ],
   "source": [
    "img=cv2.imread('mrunal.png')\n",
    "print(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 800, 3)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resize image to 300x500 pixels and save it\n",
    "resized = cv2.resize(img, (300, 500))\n",
    "cv2.imwrite('resized_mrunal.png', resized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_sai = cv2.imread('sai.png')\n",
    "if img_sai is not None:\n",
    "    resized_sai = cv2.resize(img_sai, (300, 500))\n",
    "    cv2.imshow('Original Sai', img_sai)\n",
    "    cv2.imshow('Resized Sai', resized_sai)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "else:\n",
    "    print(\"Error: Could not load sai.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = np.array([1,2,3,1,2,3])\n",
    "np.hstack((v,v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_sai = cv2.imread('sai.png')\n",
    "resized_sai = cv2.resize(img_sai, (300, 500))\n",
    "horizontal_ = np.hstack((resized_sai, resized_sai))\n",
    "cv2.imshow('Resized Sai', horizontal_)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_sai = cv2.imread('sai.png')\n",
    "resized_sai = cv2.resize(img_sai, (300, 500))\n",
    "vertical_ = np.vstack((resized_sai, resized_sai))\n",
    "cv2.imshow('Resized Sai', vertical_)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_sai = cv2.imread('sai.png')\n",
    "resized_sai = cv2.resize(img_sai, (300, 500))\n",
    "horizontal_ = np.hstack((resized_sai, resized_sai, resized_sai))\n",
    "vertical_ = np.vstack((horizontal_, horizontal_))\n",
    "cv2.imshow('Resized Sai', vertical_)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_sai = cv2.imread('sai.png')\n",
    "resized_sai = cv2.resize(img_sai, (300, 500))\n",
    "horizontal_ = np.hstack((resized_sai, resized_sai, resized_sai))\n",
    "vertical_ = np.vstack((horizontal_, horizontal_))\n",
    "cv2.imshow('Resized Sai', vertical_)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Slide `show()`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "name_list=os.listdir(\"D:\\\\DEEP LEARNING\\\\Computer Vision\\\\wscube\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['01.introduction.ipynb',\n",
       " 'allu.png',\n",
       " 'jaspreet.png',\n",
       " 'mrunal.png',\n",
       " 'ram.png',\n",
       " 'rohit.png',\n",
       " 'sai.png',\n",
       " 'sharma.png']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not read image: 01.introduction.ipynb\n"
     ]
    }
   ],
   "source": [
    "for name in name_list:\n",
    "    path=\"D:\\\\DEEP LEARNING\\\\Computer Vision\\\\wscube\"\n",
    "    img_name=path+\"\\\\\"+name\n",
    "    img=cv2.imread(img_name)\n",
    "    if img is not None:\n",
    "        resized_img = cv2.resize(img, (500, 700))\n",
    "        cv2.imshow('Test Imgs', resized_img)\n",
    "        cv2.waitKey(2000)\n",
    "        cv2.destroyAllWindows()\n",
    "    else:\n",
    "        print(f\"Could not read image: {name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not read image: 01.introduction.ipynb\n"
     ]
    }
   ],
   "source": [
    "for name in name_list:\n",
    "    path=\"D:\\\\DEEP LEARNING\\\\Computer Vision\\\\wscube\"\n",
    "    img_name=path+\"\\\\\"+name\n",
    "    img=cv2.imread(img_name)\n",
    "    if img is not None:\n",
    "        resized_img = cv2.resize(img, (500, 700))\n",
    "        cv2.imshow('Test Imgs', resized_img)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "    else:\n",
    "        print(f\"Could not read image: {name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(375, 500, 3)\n"
     ]
    }
   ],
   "source": [
    "# import cv2 \n",
    "img=cv2.imread('jaspreet.png')\n",
    "# print(img)\n",
    "print(img.shape)\n",
    "img=cv2.resize(img, (500, 500))\n",
    "cv2.imshow(\"Jaspreet\", img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **cv2.IMREAD_COLOR**: It specifies to load a color image. Any transparency of the image will be neglected. It is the default flag. Alternatively, we can pass integer value **1** for this flag.  \n",
    "\n",
    "- **cv2.IMREAD_GRAYSCALE**: It specifies to load an image in grayscale mode. Alternatively, we can pass integer value **0** for this flag.  \n",
    "\n",
    "- **cv2.IMREAD_UNCHANGED**: It specifies to load an image as is, including the alpha channel. Alternatively, we can pass integer value **-1** for this flag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(375, 500, 3)\n"
     ]
    }
   ],
   "source": [
    "# import cv2 \n",
    "img=cv2.imread('jaspreet.png', 1)\n",
    "print(img.shape)\n",
    "img=cv2.resize(img, (500, 500))\n",
    "cv2.imshow(\"Jaspreet\", img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(889, 500)\n"
     ]
    }
   ],
   "source": [
    "img = cv2.imread('allu.png', 0)  # BGR  (0-255)\n",
    "if img is not None:\n",
    "\tprint(img.shape)\n",
    "\timg = cv2.resize(img, (500, 500))\n",
    "\tcv2.imshow(\"allu\", img)\n",
    "\tcv2.waitKey(0)\n",
    "\tcv2.destroyAllWindows()\n",
    "else:\n",
    "\tprint(\"Error: Could not load virat.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 500, 3)\n"
     ]
    }
   ],
   "source": [
    "# import cv2 \n",
    "img=cv2.imread('ram.png', -1)\n",
    "print(img.shape)\n",
    "img=cv2.resize(img, (500, 500))\n",
    "cv2.imshow(\"ram\", img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BGR to RGB Conversion Done\n"
     ]
    }
   ],
   "source": [
    "## useful for Deep Learning\n",
    "import cv2\n",
    "\n",
    "img = cv2.imread('allu.png')  # Default is BGR\n",
    "if img is not None:\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert to RGB\n",
    "    print(\"BGR to RGB Conversion Done\")\n",
    "    cv2.imshow(\"RGB Image\", img_rgb)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "else:\n",
    "    print(\"Error: Could not load allu.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channels Split and Merged Successfully\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "img = cv2.imread('rohit.png')  # Load in BGR format\n",
    "if img is not None:\n",
    "    b, g, r = cv2.split(img)  # Extract individual color channels\n",
    "    merged = cv2.merge([b, g, r])  # Merge them back\n",
    "    print(\"Channels Split and Merged Successfully\")\n",
    "    cv2.imshow(\"Merged Image\", merged)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "else:\n",
    "    print(\"Error: Could not load allu.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters for cv2.putText()\n",
    "\n",
    "#### org  \n",
    "- Defines text position using (x,y) coordinates\n",
    "- x: Distance from left edge\n",
    "- y: Distance from top edge\n",
    "- Example: (50,100) places text 50 pixels from left, 100 pixels from top\n",
    "\n",
    "#### fontFace  \n",
    "Different font styles provided by OpenCV:\n",
    "- FONT_HERSHEY_SIMPLEX (0): Normal size sans-serif\n",
    "- FONT_HERSHEY_PLAIN (1): Small size sans-serif  \n",
    "- FONT_HERSHEY_DUPLEX (2): More complex sans-serif\n",
    "- FONT_HERSHEY_COMPLEX (3): More complex serif\n",
    "- FONT_HERSHEY_TRIPLEX (4): More complex serif with thicker strokes\n",
    "- FONT_HERSHEY_COMPLEX_SMALL (5): Smaller version of complex\n",
    "- FONT_HERSHEY_SCRIPT_SIMPLEX (6): Hand-writing style\n",
    "- FONT_HERSHEY_SCRIPT_COMPLEX (7): More complex hand-writing style\n",
    "\n",
    "#### color  \n",
    "- Uses BGR color format (Blue, Green, Red)\n",
    "- Values range from 0-255 for each channel\n",
    "- Example: (255,0,0) is pure blue\n",
    "\n",
    "#### lineType  \n",
    "Controls how lines/text edges are rendered:\n",
    "- FILLED (-1): Fills entire text\n",
    "- LINE_4 (4): 4-connected line\n",
    "- LINE_8 (8): 8-connected line (default)\n",
    "- LINE_AA (16): Anti-aliased line\n",
    "\n",
    "#### bottomLeftOrigin \n",
    "- Controls text origin point\n",
    "- False (default): Origin at top-left\n",
    "- True: Origin at bottom-left"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Image**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_get = cv2.imread('mrunal1.png') \n",
    "img_get = cv2.resize(img_get, (500, 500))\n",
    "img = img_get\n",
    "text = \"Mrunal\"\n",
    "org = (50, 100)\n",
    "fontFace = cv2.FONT_HERSHEY_DUPLEX\n",
    "fontScale = 3\n",
    "color = (0, 0, 255)  # BGR color format\n",
    "thickness = 3\n",
    "lineType = cv2.LINE_8\n",
    "bottomLeftOrigin = False\n",
    "\n",
    "cv2.putText(img, text, org, fontFace, fontScale, color, thickness, lineType, bottomLeftOrigin)\n",
    "\n",
    "\n",
    "cv2.imshow(\"Mrunal\", img_get)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Mrunal\"\n",
    "org1 = (50, 100)  # First text position\n",
    "org2 = (50, 200)  # Second text position, increased y-coordinate to place it below\n",
    "\n",
    "# First text\n",
    "cv2.putText(img, text, org1, fontFace, fontScale, color, thickness, lineType, bottomLeftOrigin)\n",
    "# Second text\n",
    "cv2.putText(img, text, org2, fontFace, fontScale, color, thickness, lineType, bottomLeftOrigin)\n",
    "\n",
    "cv2.imshow(\"Mrunal\", img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bounding Boxex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Line on image**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "img=cv2.imread('sai.png')\n",
    "img=cv2.resize(img, (300, 500))\n",
    "# Add line\n",
    "new_img=cv2.line(img=img, pt1=(130, 40), pt2=(200, 40), color=(0,255,0), thickness=2, lineType=4)\n",
    "cv2.imshow(\"Sai\", new_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Rectangle**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "img=cv2.imread('sai.png')\n",
    "img=cv2.resize(img, (300, 500))\n",
    "# Add line\n",
    "new_img=cv2.rectangle(img=img, pt1=(130, 35), pt2=(200, 120), color=(0,255,0), thickness=2, lineType=4)\n",
    "cv2.imshow(\"Sai\", new_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "text with rectangle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "img=cv2.imread('sai.png')\n",
    "img=cv2.resize(img, (300, 500))\n",
    "# Add rectangle\n",
    "new_img=cv2.rectangle(img=img, pt1=(130, 35), pt2=(200, 120), color=(0,255,0), thickness=2, lineType=4)\n",
    "# Add text inside rectangle\n",
    "text = \"SAI\"\n",
    "cv2.putText(new_img, text, (150, 140), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,255,0), 2, lineType)\n",
    "cv2.imshow(\"Sai\", new_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Circle on image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "img=cv2.imread('mrunal.png')\n",
    "img=cv2.resize(img, (500, 700))\n",
    "center_coordinates = (220, 150) \n",
    "radius = 80\n",
    "color = (0,255,0) \n",
    "thickness = 4\n",
    "# thickness = -1\n",
    "image = cv2.circle(img, center_coordinates, radius, color, thickness)\n",
    "cv2.imshow(\"Mrunal\", image) \n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ellipse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import cv2\n",
    "img=cv2.imread('sai.png')\n",
    "img=cv2.resize(img, (500, 700))\n",
    "image = cv2.ellipse(img=img, center=(270, 130), axes=(60, 50), angle=60, startAngle=0, endAngle=360, color=(0, 255, 0), thickness=4, lineType=16)\n",
    "cv2.imshow(\"Sai\", image) \n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np   \n",
    "Img = np.zeros((512, 512, 3), np.uint8)   \n",
    "window_name = 'Image'  \n",
    "center_coordinates = (220, 150)  \n",
    "radius, color, thickness = 100, (255, 133, 233), -1  \n",
    "\n",
    "image = cv2.circle(Img, center_coordinates, radius, color, thickness)   \n",
    "cv2.imshow(window_name, image)   \n",
    "cv2.waitKey(0)   \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
